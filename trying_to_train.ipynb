{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from resources.plotcm import plot_confusion_matrix\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "from data_generator import DataGen\n",
    "from resunetPlusPlus_pytorch import build_resunetplusplus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train steps:  3100\n",
      "valid steps:  12\n",
      "> <ipython-input-6-f456d61441b9>(56)<module>()\n",
      "-> for epoch in range(1):\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ## Path\n",
    "    file_path = \"files/\"\n",
    "    model_path = \"files/resunetplusplus.h5\"\n",
    "\n",
    "    ## Create files folder\n",
    "    try:\n",
    "        os.mkdir(\"files\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    train_path = \"new_data/kvasir_segmentation_dataset/train/\"\n",
    "    valid_path = \"new_data/kvasir_segmentation_dataset/valid/\"\n",
    "\n",
    "    ## Training\n",
    "    train_image_paths = glob(os.path.join(train_path, \"images\", \"*\"))\n",
    "    train_mask_paths = glob(os.path.join(train_path, \"masks\", \"*\"))\n",
    "    train_image_paths.sort()\n",
    "    train_mask_paths.sort()\n",
    "\n",
    "    # train_image_paths = train_image_paths[:2000]\n",
    "    # train_mask_paths = train_mask_paths[:2000]\n",
    "\n",
    "    ## Validation\n",
    "    valid_image_paths = glob(os.path.join(valid_path, \"images\", \"*\"))\n",
    "    valid_mask_paths = glob(os.path.join(valid_path, \"masks\", \"*\"))\n",
    "    valid_image_paths.sort()\n",
    "    valid_mask_paths.sort()\n",
    "    \n",
    "    ## Parameters\n",
    "    image_size = 256\n",
    "    batch_size = 8\n",
    "    lr = 1e-4\n",
    "    epochs = 200\n",
    "    \n",
    "    train_steps = len(train_image_paths)//batch_size\n",
    "    print(\"train steps: \", train_steps)\n",
    "    valid_steps = len(valid_image_paths)//batch_size\n",
    "    print(\"valid steps: \", valid_steps)\n",
    "    \n",
    "    train_gen = DataGen(image_size, train_image_paths, train_mask_paths, batch_size=batch_size)\n",
    "    valid_gen = DataGen(image_size, valid_image_paths, valid_mask_paths, batch_size=batch_size)\n",
    "    \n",
    "    ## Turn the data into a torch.utils.data thing\n",
    "    train_loader = torch.utils.data.DataLoader(train_gen, batch_size=8)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_gen, batch_size=8)\n",
    "    \n",
    "    ## ResUnet++\n",
    "    model = build_resunetplusplus()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    \n",
    "    breakpoint()\n",
    "    # The training loop\n",
    "    for epoch in range(1):\n",
    "        total_correct = 0\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(images)\n",
    "\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step( )\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_correct += preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "        print('epoch:', epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
